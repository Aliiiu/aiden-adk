import type { LanguageModel } from "ai";
import axios from "axios";
import { Tiktoken } from "js-tiktoken/lite";
import cl100k_base from "js-tiktoken/ranks/cl100k_base";
import { env } from "../../../env";
import { createChildLogger } from "../../../lib/utils";
import { toMarkdown } from "../../../lib/utils/markdown-formatter";
import { LLMDataFilter } from "../../debank-mcp/utils/data-filter";
import { config } from "../config";

const logger = createChildLogger("DefiLlama Base Service");

// Initialize tiktoken encoder for token counting
const encoder = new Tiktoken(cl100k_base);

/**
 * Base Service for DefiLlama API
 * Provides common caching and data fetching functionality
 */
export abstract class BaseService {
	protected aiModel?: LanguageModel;
	protected dataFilter?: LLMDataFilter;
	protected currentQuery?: string;
	protected rawOutput = false;

	/**
	 * Set the AI model for data filtering
	 * Call this method to enable automatic filtering of large responses
	 */
	setAIModel(model: LanguageModel) {
		this.aiModel = model;
		this.dataFilter = new LLMDataFilter({ model });
	}

	/**
	 * Set the current user query for context-aware filtering
	 * This should be called before making service requests
	 */
	setQuery(query: string) {
		this.currentQuery = query;
	}

	/**
	 * Toggle raw output mode. When true, service
	 * methods return raw JSON instead of formatted markdown.
	 */
	setRawOutput(raw: boolean) {
		this.rawOutput = raw;
	}

	protected readonly BASE_URL = "https://api.llama.fi";
	protected readonly COINS_URL = "https://coins.llama.fi";
	protected readonly STABLECOINS_URL = "https://stablecoins.llama.fi";
	protected readonly YIELDS_URL = "https://yields.llama.fi";
	protected readonly DEFAULT_CACHE_TTL_SECONDS = 60 * 60; // 1 hour

	protected async fetchData<T>(
		url: string,
		cacheDurationSeconds: number = this.DEFAULT_CACHE_TTL_SECONDS,
	): Promise<T> {
		const proxyUrl = new URL(env.IQ_GATEWAY_URL);
		proxyUrl.searchParams.append("url", url);
		proxyUrl.searchParams.append("projectName", "defillama_mcp");
		if (cacheDurationSeconds >= 0) {
			proxyUrl.searchParams.append(
				"cacheDuration",
				Math.floor(cacheDurationSeconds).toString(),
			);
		}

		try {
			const response = await axios.get<T>(proxyUrl.href, {
				headers: {
					"Content-Type": "application/json",
					"x-api-key": env.IQ_GATEWAY_KEY,
				},
			});
			return response.data;
		} catch (error: unknown) {
			if (axios.isAxiosError(error)) {
				const errorPayload = error.response?.data ?? error.message;
				const errorMessage =
					typeof errorPayload === "string"
						? errorPayload
						: JSON.stringify(errorPayload);
				throw new Error(errorMessage);
			}
			throw error instanceof Error ? error : new Error(String(error));
		}
	}

	protected toUnixSeconds(value: string | number): number {
		if (typeof value === "number") {
			return Math.floor(value);
		}

		const trimmed = value.trim();
		if (/^\d+$/.test(trimmed)) {
			return Math.floor(Number(trimmed));
		}

		const parsed = Date.parse(trimmed);
		if (Number.isNaN(parsed)) {
			throw new Error(`Invalid timestamp value: ${value}`);
		}

		return Math.floor(parsed / 1000);
	}

	/**
	 * Format response for LLM consumption
	 * Returns MCP-compliant response with content array
	 * Automatically filters large responses if AI model is configured
	 * Uses currentQuery set via setQuery() for filtering context
	 */
	protected async formatResponse(
		data: unknown,
		options?: {
			title?: string;
			currencyFields?: string[];
			numberFields?: string[];
		},
	): Promise<any> {
		if (this.rawOutput) {
			return data;
		}

		let markdownOutput = toMarkdown(data, options);

		const tokenLength = encoder.encode(markdownOutput).length;
		logger.info(`Response token length: ${tokenLength}`);
		logger.info(
			`Response token need filtering: ${tokenLength > config.maxTokens ? "Yes" : "No"}`,
		);
		logger.info(
			`User query for filtering: ${this.currentQuery ? "Yes" : "No"}`,
		);
		logger.info(`Data filter configured: ${this.dataFilter ? "Yes" : "No"}`);

		if (
			tokenLength > config.maxTokens &&
			this.dataFilter &&
			this.currentQuery
		) {
			try {
				const jsonData = JSON.stringify(data);
				const filteredJson = await this.dataFilter.filter(
					jsonData,
					this.currentQuery,
				);
				markdownOutput = toMarkdown(JSON.parse(filteredJson), {
					title: options?.title,
					currencyFields: options?.currencyFields,
					numberFields: options?.numberFields,
				});

				const tokenLength = encoder.encode(markdownOutput).length;
				logger.info(`New Response token length: ${tokenLength}`);

				return markdownOutput;
			} catch (error) {
				console.error("Error filtering response:", error);
				return markdownOutput;
			}
		}

		return markdownOutput;
	}
}
